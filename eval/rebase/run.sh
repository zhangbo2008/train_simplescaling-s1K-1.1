O1INFERENCE=1 PROMPTSTEP=64 O1INFERENCE_NUM_PARALLEL_STEPS=16 OPENAI_API_KEY=YOUR_OPENAI_KEY PROCESSOR=gpt-4o-mini HF_TOKEN=YOUR_HF_KEY lm_eval --model vllm --model_args pretrained=qfq/Qwen2.5-32B-Instruct-20250119_185226,tokenizer=Qwen/Qwen2.5-32B-Instruct,dtype=float32,tensor_parallel_size=8 --tasks aime24_figures,aime24_nofigures,openai_math,gpqa_diamond_openai --batch_size auto --apply_chat_template --output_path promptstep16forcinganwer --log_samples --gen_kwargs "max_gen_toks=32768,max_tokens_thinking=auto,thinking_start=<|im_start|>,thinking_end=<|im_start|>answer
Final Answer:,until_thinking=<|im_start|>0"